_index,DATE,ITER,TIME_ITER,capability,cpu,date_start,device,device_name,discrepancies_abs,discrepancies_rel,dtype,dump_folder,dump_ort,dynamic,executable,exporter,filename,flag_fake_tensor,flag_no_grad,flag_training,has_cuda,input_size,machine,mema_gpu_0_before_loading,mema_gpu_1_after_loading,mema_gpu_2_after_warmup,mema_gpu_3_empty_cache,mema_gpu_4_after_repeat,mema_gpu_5_after_export,mema_gpu_6_after_gcollect,mema_gpu_7_after_session,mema_gpu_8_after_export_warmup,mema_gpu_9_after_export_repeat,memory_begin,memory_end,memory_gpu0_begin,memory_gpu0_end,memory_gpu0_mean,memory_gpu0_n,memory_gpu0_peak,memory_gpu1_begin,memory_gpu1_end,memory_gpu1_mean,memory_gpu1_n,memory_gpu1_peak,memory_gpu2_begin,memory_gpu2_end,memory_gpu2_mean,memory_gpu2_n,memory_gpu2_peak,memory_gpu3_begin,memory_gpu3_end,memory_gpu3_mean,memory_gpu3_n,memory_gpu3_peak,memory_gpu4_begin,memory_gpu4_end,memory_gpu4_mean,memory_gpu4_n,memory_gpu4_peak,memory_gpu5_begin,memory_gpu5_end,memory_gpu5_mean,memory_gpu5_n,memory_gpu5_peak,memory_gpu6_begin,memory_gpu6_end,memory_gpu6_mean,memory_gpu6_n,memory_gpu6_peak,memory_gpu7_begin,memory_gpu7_end,memory_gpu7_mean,memory_gpu7_n,memory_gpu7_peak,memory_mean,memory_n,memory_peak,model,model_name,nvtx,onnx_filesize,onnx_input_names,onnx_model,onnx_n_functions,onnx_n_initializer,onnx_n_inputs,onnx_n_nodes,onnx_n_outputs,onnx_n_sequence,onnx_n_sparse_initializer,onnx_opt_added,onnx_opt_max_iter,onnx_opt_n_applied,onnx_opt_removed,onnx_opt_time_in,onnx_opt_unique_applied,onnx_opt_unique_matched,onnx_optimized,onnx_output_names,op_onnx_Add,op_onnx_Cast,op_onnx_ConstantOfShape,op_onnx_Expand,op_onnx_Gather,op_onnx_LayerNormalization,op_onnx_MatMul,op_onnx_Mul,op_onnx_Pow,op_onnx_Reshape,op_onnx_Softmax,op_onnx_SoftmaxCrossEntropyLoss,op_onnx_Sub,op_onnx_Tanh,op_onnx_Transpose,op_onnx_Unsqueeze,op_onnx_initializer,op_onnx_onnx_extended.ortops.optim.cuda_AddAdd,op_onnx_onnx_extended.ortops.optim.cuda_MulAdd,op_onnx_onnx_extended.ortops.optim.cuda_MulMul,op_onnx_onnx_extended.ortops.optim.cuda_MulSub,op_onnx_sparse_initializer,op_torch_aten._to_copy.default,op_torch_aten._unsafe_view.default,op_torch_aten.add.Tensor,op_torch_aten.clone.default,op_torch_aten.cross_entropy_loss.default,op_torch_aten.div.Tensor,op_torch_aten.dropout.default,op_torch_aten.embedding.default,op_torch_aten.expand.default,op_torch_aten.layer_norm.default,op_torch_aten.linear.default,op_torch_aten.matmul.default,op_torch_aten.mul.Tensor,op_torch_aten.ones.default,op_torch_aten.permute.default,op_torch_aten.pow.Tensor_Scalar,op_torch_aten.rsub.Scalar,op_torch_aten.slice.Tensor,op_torch_aten.softmax.int,op_torch_aten.tanh.default,op_torch_aten.transpose.int,op_torch_aten.unsqueeze.default,op_torch_aten.view.default,opt_patterns,output_data,output_size,params_dtype,params_size,processor,providers,quiet,repeat,speedup,speedup_increase,start,suite,target_opset,time_export,time_export_success,time_latency,time_latency_eager,time_load,time_session,time_total,time_warmup,time_warmup_eager,verbose,version,version_onnx,version_onnxruntime,version_onnxscript,version_torch,version_transformers,warmup,ERROR,OUTPUT,CMD
AlbertForMaskedLM-custom,2024-07-19,0,32.69604991702363,7.0,40,2024-07-19,cuda,Tesla V100-SXM2-32GB,0.001953125,1.298828125,float16,dump_bash_bench,0,0,/usr/bin/python3,custom,dump_bash_bench/AlbertForMaskedLM-custom-cuda-torch.float16-default/model.onnx,False,True,False,True,4096,x86_64,0,412780544,421300224,421300224,421300224,421300224,421300224,421300224,421300224,421300224,1012.25390625,6077.81640625,1447.5625,1835.5625,1820.476963452566,643,1835.5625,277.5625,277.5625,277.5625,643,277.5625,277.5625,277.5625,277.5625,643,277.5625,277.5625,277.5625,277.5625,643,277.5625,277.5625,277.5625,277.5625,643,277.5625,277.5625,277.5625,277.5625,643,277.5625,277.5625,277.5625,277.5625,643,277.5625,277.5625,277.5625,277.5625,643,277.5625,2800.2984119848365,643,1,AlbertForMaskedLM,AlbertForMaskedLM,0,88572,args_0|args_6,1,0,150,2,474,2,0,0,610,3,270,1374,1.360550133162178,8,31,1,output_0|output_1,64,1,1,1,3,26,99,65,13,50,12,1,1.0,13,123,1,150,,,,,0,1,12,64,12,1,12,25,3,1,26,75,24,53,1,36,13,1,2,12,13,24,2,38,default,,61440001.0,float16,206368944,x86_64,CUDAExecutionProvider_CPUExecutionProvider,1,30,1.247673155309508,0.24767315530950795,0,HuggingFace,18,6.633711165981367,6.633713465998881,0.12554645830144484,0.15664094576689724,2.8930972010130063,4.177878852002323,26.008220520918258,0.1295681763906032,0.16310649949591607,1,3.9.19,1.16.1,1.19.0+cu118,dev,2.5.0.dev20240718+cu118,4.37.2,10,.local/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download_ use `force_download=True`. --   warnings.warn( -- [,[bash_bench_huggingface] start -- device=cuda -- dtype=float16 -- dump_folder=dump_bash_bench -- dump_ort=0 -- dynamic=0 -- exporter=custom -- memory_peak=1 -- model=AlbertForMaskedLM -- nvtx=0 -- opt_patterns=default -- output_data= -- process=0 -- quiet=1 -- repeat=30 -- start=0 -- target_opset=18,[/usr/bin/python3 -m experimental_experiment.torch_bench.bash_bench_huggingface --repeat 30 --warmup 10 --model AlbertForMaskedLM --exporter custom --device cuda --dynamic 0 --target_opset 18 --verbose 1 --opt_patterns default --dump_folder dump_bash_bench --quiet 1 --start 0 --dtype float16 --outpu
AlbertForMaskedLM-custom,2024-07-19,1,33.46586319396738,7.0,40,2024-07-19,cuda,Tesla V100-SXM2-32GB,0.0020751953125,1.4404296875,float16,dump_bash_bench,0,0,/usr/bin/python3,custom,dump_bash_bench/AlbertForMaskedLM-custom-cuda-torch.float16-default_experimental/model.onnx,False,True,False,True,4096,x86_64,0,412780544,421300224,421300224,421300224,421300224,421300224,421300224,421300224,421300224,1013.61328125,6080.9375,1447.5625,1835.5625,1820.2985248447205,644,1835.5625,277.5625,277.5625,277.5625,644,277.5625,277.5625,277.5625,277.5625,644,277.5625,277.5625,277.5625,277.5625,644,277.5625,277.5625,277.5625,277.5625,644,277.5625,277.5625,277.5625,277.5625,644,277.5625,277.5625,277.5625,277.5625,644,277.5625,277.5625,277.5625,277.5625,644,277.5625,2809.406650329969,644,1,AlbertForMaskedLM,AlbertForMaskedLM,0,89045,args_0|args_6,1,0,150,2,446,2,0,0,638,6,298,1458,1.6490559187950566,11,48,1,output_0|output_1,49,1,1,1,3,26,99,25,13,50,12,1,,13,123,1,150,1.0,13.0,13.0,1.0,0,1,12,64,12,1,12,25,3,1,26,75,24,53,1,36,13,1,2,12,13,24,2,38,default+experimental,,61440001.0,float16,206368944,x86_64,CUDAExecutionProvider_CPUExecutionProvider,1,30,1.1130667610137968,0.11306676101379676,0,HuggingFace,18,6.662149948999286,6.662152849021368,0.14179535899699355,0.15782770096557214,2.8999685070011765,4.310180519009009,26.923143320949748,0.14708033259958028,0.162799475598149,1,3.9.19,1.16.1,1.19.0+cu118,dev,2.5.0.dev20240718+cu118,4.37.2,10,.local/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download_ use `force_download=True`. --   warnings.warn( -- [,[bash_bench_huggingface] start -- device=cuda -- dtype=float16 -- dump_folder=dump_bash_bench -- dump_ort=0 -- dynamic=0 -- exporter=custom -- memory_peak=1 -- model=AlbertForMaskedLM -- nvtx=0 -- opt_patterns=default+experimental -- output_data= -- process=0 -- quiet=1 -- repeat=30 -- start=0 -- ta,[/usr/bin/python3 -m experimental_experiment.torch_bench.bash_bench_huggingface --repeat 30 --warmup 10 --model AlbertForMaskedLM --exporter custom --device cuda --dynamic 0 --target_opset 18 --verbose 1 --opt_patterns default+experimental --dump_folder dump_bash_bench --quiet 1 --start 0 --dtype fl
